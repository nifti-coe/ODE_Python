{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callin Switzer\n",
    "### 16 Jan 2020\n",
    "### Simulate data for training neural network \n",
    "### This uses the \"one torque\" or  the \"underactuated\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 (default, Feb 28 2019, 07:28:18) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import simUtils_one_torque # note that this is a custom-written file \n",
    "import importlib\n",
    "import functools\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last run on 2020-01-27 12:27:16.737099\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "pythonMadeData = r\"D:/Dropbox/AcademiaDropbox/mothMachineLearning_dataAndFigs/PythonGeneratedData_oneTorque\"\n",
    "\n",
    "if not os.path.exists(pythonMadeData):\n",
    "    os.mkdir(pythonMadeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "_ = importlib.reload(simUtils_one_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save global options\n",
    "\n",
    "globalDict = OrderedDict({\n",
    "            \"bhead\": 0.5,\n",
    "            \"ahead\": 0.9,\n",
    "            \"bbutt\": 0.75,\n",
    "            \"abutt\": 1.9, \n",
    "            \"rho_head\": 0.9,\n",
    "            \"rho_butt\": 0.4,\n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.9, \n",
    "            \"L2\": 1.9,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 23000,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 2, # return start and endpoints\n",
    "            \"nrun\" : 1000000 # (max) number of  trajectories.\n",
    "            })\n",
    "\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho_head']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho_butt\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]\n",
    "\n",
    "\n",
    "# ranges for control variables\n",
    "rangeDict = {\"Fmin\": 0,\n",
    "             \"Fmax\": 44300,\n",
    "             \"alphaMin\":  0,\n",
    "             \"alphaMax\":2*np.pi, \n",
    "             \"tau0Min\": -100000, \n",
    "             \"tau0Max\": 100000}\n",
    "\n",
    "# ranges for controls \n",
    "ranges = np.array([[rangeDict[\"Fmin\"], rangeDict[\"Fmax\"]], \n",
    "                   [rangeDict[\"alphaMin\"], rangeDict[\"alphaMax\"]], \n",
    "                   [rangeDict[\"tau0Min\"], rangeDict[\"tau0Max\"] ]])\n",
    "\n",
    "# ranges for initial conditions\n",
    "IC_ranges = np.array([[0, 0],        #x\n",
    "                      [-1500, 1500], #xdot  \n",
    "                      [0, 0],        #y\n",
    "                      [-1500, 1500], #ydot\n",
    "                      [0, 2*np.pi],  #theta\n",
    "                      [-25, 25],     #theta dot\n",
    "                      [0, 2*np.pi],  #phi\n",
    "                      [-25, 25]])    # phi dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "time for one run: 140.420916557312\n",
      "1\n",
      "time for one run: 141.9707088470459\n",
      "2\n",
      "time for one run: 133.71944522857666\n",
      "3\n",
      "time for one run: 132.46256637573242\n",
      "4\n",
      "time for one run: 145.3727912902832\n",
      "5\n",
      "time for one run: 132.75297021865845\n",
      "6\n",
      "time for one run: 134.24939966201782\n",
      "7\n",
      "time for one run: 139.1135127544403\n",
      "8\n",
      "time for one run: 145.1470263004303\n",
      "9\n",
      "time for one run: 137.68755626678467\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "\n",
    "dataType = \"trainingData_\"\n",
    "for ii in np.arange(0,10):\n",
    "    print(ii)\n",
    "\n",
    "    # generate random ICs and controls\n",
    "    # random F, alpha, tau, tau_w\n",
    "    FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                       size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "    # random initial conditions for state 0\n",
    "    state0_ICs = np.random.uniform(IC_ranges[:, 0], IC_ranges[:, 1], size=(globalDict[\"nrun\"], IC_ranges.shape[0]))\n",
    "\n",
    "    # run simulations in parallel, \"nrun\"s at a time\n",
    "    p = Pool(cpu_count() - 2)\n",
    "    stt = time.time()\n",
    "    bb = p.map(functools.partial(simUtils_one_torque.flyBug_listInput_oneTorque, t=t, \n",
    "                                  state0_ICs = state0_ICs, \n",
    "                                  FAlphaTau_list= FAlphaTau_list, \n",
    "                                  globalList = globalList), range(globalDict[\"nrun\"]))\n",
    "    print(\"time for one run:\", time.time() - stt)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    # reshape to put into a pd data frame\n",
    "    bb2 = np.array(bb).reshape(globalDict[\"nrun\"], -1, order = \"F\")\n",
    "    bb3 = np.hstack([bb2, FAlphaTau_list])\n",
    "\n",
    "    simDF = pd.DataFrame(bb3, columns =  [\"x_0\", \"xd_0\",\"y_0\",\"yd_0\",\n",
    "                                         \"theta_0\",\"thetad_0\",\"phi_0\",\"phid_0\", \n",
    "                                         \"x_f\", \"xd_f\",\"y_f\",\"yd_f\",\n",
    "                                         \"theta_f\",\"thetad_f\",\"phi_f\",\"phid_f\", \n",
    "                                              \"F\", \"alpha\", \"tau0\"])\n",
    "\n",
    "    # write to database, \n",
    "    # makes a new database if it doesn't already exist\n",
    "    con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "\n",
    "\n",
    "    # get table names from database\n",
    "    try:\n",
    "        cursorObj = con1.cursor()\n",
    "        cursorObj.execute('SELECT name from sqlite_master where type= \"table\"')\n",
    "        tableNames = cursorObj.fetchall()\n",
    "        cursorObj.close()\n",
    "    except:\n",
    "        print(\"can't get table names\")\n",
    "\n",
    "    # refref: name changed from \"trainingData_\" to \"testingData_\" when I generated new data\n",
    "    simDF.to_sql(dataType + str(len(tableNames)).zfill(2), con1, if_exists = \"fail\", index = False)\n",
    "    \n",
    "    # close connection\n",
    "    con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "time for one run: 141.77251172065735\n",
      "1\n",
      "time for one run: 140.0630223751068\n",
      "2\n",
      "time for one run: 154.1449887752533\n",
      "3\n",
      "time for one run: 137.77385926246643\n",
      "4\n",
      "time for one run: 143.83664083480835\n"
     ]
    }
   ],
   "source": [
    "dataType = \"testingData_\"\n",
    "for ii in np.arange(0,5):\n",
    "    print(ii)\n",
    "\n",
    "    # generate random ICs and controls\n",
    "    # random F, alpha, tau, tau_w\n",
    "    FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                       size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "    # random initial conditions for state 0\n",
    "    state0_ICs = np.random.uniform(IC_ranges[:, 0], IC_ranges[:, 1], size=(globalDict[\"nrun\"], IC_ranges.shape[0]))\n",
    "\n",
    "    # run simulations in parallel, \"nrun\"s at a time\n",
    "    p = Pool(cpu_count() - 2)\n",
    "    stt = time.time()\n",
    "    bb = p.map(functools.partial(simUtils_one_torque.flyBug_listInput_oneTorque, t=t, \n",
    "                                  state0_ICs = state0_ICs, \n",
    "                                  FAlphaTau_list= FAlphaTau_list, \n",
    "                                  globalList = globalList), range(globalDict[\"nrun\"]))\n",
    "    print(\"time for one run:\", time.time() - stt)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    # reshape to put into a pd data frame\n",
    "    bb2 = np.array(bb).reshape(globalDict[\"nrun\"], -1, order = \"F\")\n",
    "    bb3 = np.hstack([bb2, FAlphaTau_list])\n",
    "\n",
    "    simDF = pd.DataFrame(bb3, columns =  [\"x_0\", \"xd_0\",\"y_0\",\"yd_0\",\n",
    "                                         \"theta_0\",\"thetad_0\",\"phi_0\",\"phid_0\", \n",
    "                                         \"x_f\", \"xd_f\",\"y_f\",\"yd_f\",\n",
    "                                         \"theta_f\",\"thetad_f\",\"phi_f\",\"phid_f\", \n",
    "                                              \"F\", \"alpha\", \"tau0\"])\n",
    "\n",
    "    # write to database, \n",
    "    # makes a new database if it doesn't already exist\n",
    "    con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "\n",
    "\n",
    "    # get table names from database\n",
    "    try:\n",
    "        cursorObj = con1.cursor()\n",
    "        cursorObj.execute('SELECT name from sqlite_master where type= \"table\"')\n",
    "        tableNames = cursorObj.fetchall()\n",
    "        cursorObj.close()\n",
    "    except:\n",
    "        print(\"can't get table names\")\n",
    "\n",
    "    # refref: name changed from \"trainingData_\" to \"testingData_\" when I generated new data\n",
    "    simDF.to_sql(dataType + str(len(tableNames)).zfill(2), con1, if_exists = \"fail\", index = False)\n",
    "    \n",
    "    # close connection\n",
    "    con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainingData_00', 'trainingData_01', 'trainingData_02', 'trainingData_03', 'trainingData_04', 'trainingData_05', 'trainingData_06', 'trainingData_07', 'trainingData_08', 'trainingData_09', 'testingData_10', 'testingData_11', 'testingData_12', 'testingData_13', 'testingData_14']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE test AS SELECT * FROM testingData_10 UNION ALL SELECT * FROM testingData_11 UNION ALL SELECT * FROM testingData_12 UNION ALL SELECT * FROM testingData_13 UNION ALL SELECT * FROM testingData_14\n"
     ]
    }
   ],
   "source": [
    " # Combine testing Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "con1.execute(\"DROP TABLE IF EXISTS test\")\n",
    "sqlStatement = \"CREATE TABLE test AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE train AS SELECT * FROM trainingData_00 UNION ALL SELECT * FROM trainingData_01 UNION ALL SELECT * FROM trainingData_02 UNION ALL SELECT * FROM trainingData_03 UNION ALL SELECT * FROM trainingData_04 UNION ALL SELECT * FROM trainingData_05 UNION ALL SELECT * FROM trainingData_06 UNION ALL SELECT * FROM trainingData_07 UNION ALL SELECT * FROM trainingData_08 UNION ALL SELECT * FROM trainingData_09\n"
     ]
    }
   ],
   "source": [
    "# Combine Training Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "con1.execute(\"DROP TABLE IF EXISTS train\")\n",
    "sqlStatement = \"CREATE TABLE train AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows: 10000000\n",
      "\n",
      "Total rows: 5000000\n"
     ]
    }
   ],
   "source": [
    "# print print the max row number\n",
    "def largestRowNumber(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns the total number of rows in the database \"\"\"\n",
    "    cursor.execute(\"SELECT max(rowid) from  {}\".format(table_name))\n",
    "    n = cursor.fetchone()[0]\n",
    "    if print_out:\n",
    "        print('\\nTotal rows: {}'.format(n))\n",
    "    return(n)\n",
    "\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "largestRowNumber(cursorObj, \"train\", print_out=True)\n",
    "largestRowNumber(cursorObj, \"test\", print_out=True)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS trainingData_00; DROP TABLE IF EXISTS trainingData_01; DROP TABLE IF EXISTS trainingData_02; DROP TABLE IF EXISTS trainingData_03; DROP TABLE IF EXISTS trainingData_04; DROP TABLE IF EXISTS trainingData_05; DROP TABLE IF EXISTS trainingData_06; DROP TABLE IF EXISTS trainingData_07; DROP TABLE IF EXISTS trainingData_08; DROP TABLE IF EXISTS trainingData_09; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller training datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS testingData_10; DROP TABLE IF EXISTS testingData_11; DROP TABLE IF EXISTS testingData_12; DROP TABLE IF EXISTS testingData_13; DROP TABLE IF EXISTS testingData_14; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller testing datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"oneTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "numSolve_parallel",
   "language": "python",
   "name": "numsolve_parallel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
